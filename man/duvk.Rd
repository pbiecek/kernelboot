% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/univar-kd.R
\name{duvk}
\alias{duvk}
\alias{ruvk}
\title{Univariate kernel density}
\usage{
duvk(x, y, bw = bw.nrd0(y), kernel = c("gaussian", "epanechnikov",
  "rectangular", "triangular", "biweight", "triweight", "cosine", "optcosine"),
  weights = NULL, adjust = 1, log.prob = FALSE)

ruvk(n, y, bw = bw.nrd0(y), kernel = c("gaussian", "epanechnikov",
  "rectangular", "triangular", "biweight", "triweight", "cosine", "optcosine"),
  weights = NULL, adjust = 1, preserve.var = FALSE)
}
\arguments{
\item{x}{numeric vector of length \eqn{k}; kernel density is
evaluated on those values.}

\item{y}{numeric vector of length \eqn{n}; kernel density is
evaluated on those values.}

\item{bw}{the smoothing bandwidth to be used. The kernels are scaled
such that this is the standard deviation of the smoothing
kernel (see \code{\link[stats]{density}} for details).}

\item{kernel}{a character string giving the smoothing kernel to be used.
This must partially match one of "gaussian", "rectangular",
"triangular", "epanechnikov", "biweight", "triweight", "cosine"
or "optcosine", with default "gaussian", and may be abbreviated.}

\item{weights}{numeric vector of length \eqn{n}; must be non-negative.}

\item{adjust}{scalar; the bandwidth used is actually \code{adjust*bw}.
This makes it easy to specify values like 'half the default'
bandwidth.}

\item{log.prob}{logical; if \code{TRUE}, probabilities p are given as log(p).}

\item{n}{number of observations. If length(n) > 1,
the length is taken to be the number required.}

\item{preserve.var}{logical; if \code{TRUE} random generation algorithm preserves
variance of the original sample.}
}
\description{
Univariate kernel density
}
\details{
Univariate kernel density estimator is defined as

\deqn{
\hat{f_h}(x) = \sum_{i=1}^n w_i \, K_h\left(\frac{x-y_i}{h}\right)
}{
f(x) = sum[i](w[i] * Kh((x-y[i])/h))
}

where \eqn{w} is a vector of weights such that \eqn{\sum_i w_i = 1}{sum(w) = 1}
(by default \eqn{w_i=1/n}{w[i]=1/n} for all \eqn{i}), \eqn{K_h = K(x/h)/h}{Kh = K(x/h)/h} is
kernel \eqn{K} parametrized by bandwidth \eqn{h} and \eqn{y} is a vector of
data points used for estimating the kernel density.

To draw samples from univariate kernel density, the following procedure can be applied (Silverman, 1986):

\emph{Step 1} Sample \eqn{i} uniformly with replacement from \eqn{1,\dots,n}.

\emph{Step 2} Generate \eqn{\varepsilon}{\epsilon} to have probability density \eqn{K}.

\emph{Step 3} Set \eqn{Y = X_i + h\varepsilon}{Y = X[i] + h\epsilon}.

If samples are required to have the same variance as \code{data}
(i.e. \code{preserve.var = TRUE}), then \emph{Step 3} is modified
as following:

\emph{Step 3'} \eqn{
Y = \hat X + (X_i - \hat X + h\varepsilon)/(1 + h^2 \sigma^2_K/\sigma^2_X)^{1/2}
}{
Y = m + (X[i] - m + h\epsilon)/(1 + h^2 var(K)/var(X))^(1/2)
}


\strong{Available univariate kernels}

This package offers the following univariate kernels:

\emph{Gaussian}
\deqn{
K(u) = \frac{1}{\sqrt{2\pi}} e^{-{u^2}/2}
}{
K(u) = 1/sqrt(2\pi) exp(-(u^2)/2)
}

\emph{Rectangular}
\deqn{
K(u) = \frac{1}{2} \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = 1/2
}

\emph{Triangular}
\deqn{
K(u) = (1-|u|) \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = (1 - |u|)
}

\emph{Epanchenikov}
\deqn{
K(u) = \frac{3}{4}(1-u^2) \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = 3/4 (1 - u^2)
}

\emph{Biweight}
\deqn{
K(u) = \frac{15}{16}(1-u^2)^2 \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = 15/16 (1 - u^2)^2
}

\emph{Triweight}
\deqn{
K(u) = \frac{35}{32}(1-u^2)^3 \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = 35/32 (1 - u^2)^3
}

\emph{Cosine}
\deqn{
K(u) = \frac{1}{2} \left(1 + \cos(\pi u)\right) \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = 1/2 (1 + cos(\pi u))
}

\emph{Optcosine}
\deqn{
K(u) = \frac{\pi}{4}\cos\left(\frac{\pi}{2}u\right) \ \mathbf{1}_{(|u|\leq1)}
}{
K(u) = \pi/4 cos(\pi/2 u)
}

Random generation from Epachenikov kernel is done using algorithm
described by Devoye (1986). For optcosine kernel inverse transform
sampling is used. For biweight kernel random values are drawn from
\eqn{\mathrm{Beta}(3, 3)}{Beta(3, 3)} distribution, for triweight
kernel from \eqn{\mathrm{Beta}(4, 4)}{Beta(4, 4)} distribution,
and \eqn{\mathrm{Beta}(3.3575, 3.3575)}{Beta(3.3575, 3.3575)}
distribution serves as a close approximation of cosine kernel.
Random generation for triangular kernel is done by taking difference
of two i.i.d. uniform random variates. To sample from rectangular
and Gaussian kernels standard random generation algorithms are used
(see \code{\link[stats]{runif}} and \code{\link[stats]{rnorm}}).
}
\examples{

hist(ruvk(1e5, mtcars$mpg), 100, freq = FALSE)
curve(duvk(x, mtcars$mpg), from = 0, to = 50, col = "red", add = TRUE)

hist(ruvk(1e5, mtcars$mpg, preserve.var = TRUE), 100, freq = FALSE)
curve(duvk(x, mtcars$mpg), from = 0, to = 50, col = "red", add = TRUE)


}
\references{
Silverman, B.W. (1986). Density estimation for statistics and data analysis. Chapman and Hall/CRC.

Wand, M.P. and Jones, M.C. (1995). Kernel Smoothing. Chapman and Hall/CRC.

Scott, D.W. (1992). Multivariate density estimation: theory, practice,
and visualization. John Wiley & Sons.

Devroye, L. (1986). Non-Uniform Random Variate Generation. New York: Springer-Verlag.

Parzen, E. (1962). On estimation of a probability density function and mode.
The annals of mathematical statistics, 33(3), 1065-1076.
}
\seealso{
\code{\link[stats]{density}}, \code{\link{kernelboot}}
}
